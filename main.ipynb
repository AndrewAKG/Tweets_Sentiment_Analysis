{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import uritools\n",
    "import urlextract\n",
    "from langdetect import detect\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Read\n"
     ]
    }
   ],
   "source": [
    "extractor = urlextract.URLExtract()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "data = {'airline_sentiment':[],'text':[]}\n",
    "airline_sentiment = []\n",
    "corpus = []\n",
    "\n",
    "with open('Tweets.csv', 'r', encoding='utf8') as f:\n",
    "    tweets = csv.reader(f)\n",
    "    for row in tweets:        \n",
    "        data['airline_sentiment'].append(row[1])\n",
    "        data['text'].append(row[10])\n",
    "\n",
    "print(\"Data Read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing, Stemming, CaseFolding and Removing Stop Words from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(words):\n",
    "    urls = extractor.find_urls(words+\" \")\n",
    "    for url in urls:\n",
    "        words = words.replace(url,'')\n",
    "    tknzr = TweetTokenizer()\n",
    "    words = tknzr.tokenize(words)\n",
    "    exclude = set(string.punctuation)\n",
    "    words = [word.lower() for word in words if not word.lower() in exclude]\n",
    "    words = [word.lower() for word in words \n",
    "            if not word in set(stopwords.words('english')) and not word.isdigit()]\n",
    "    words = [ps.stem(word) for word in words]\n",
    "    words = ' '.join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanWithoutFilter():\n",
    "    corpus = []\n",
    "    corpusText=''\n",
    "    with open('Tweets.csv',  encoding='utf8') as File:\n",
    "        spamreader = csv.reader(File)\n",
    "        for row in spamreader:       \n",
    "            corpusText =  clean(row[10])\n",
    "            corpus.append(corpusText)\n",
    "    return corpus\n",
    "\n",
    "def CleanWithFilter():\n",
    "    corpus = []\n",
    "    corpusText=''\n",
    "    counter = 0\n",
    "    with open('Tweets.csv',  encoding='utf8') as File:\n",
    "        spamreader = csv.reader(File)\n",
    "        for row in spamreader:       \n",
    "            corpusText =  clean(row[10])\n",
    "            if(not(corpusText.__contains__(\"RT\") or (len(corpusText )<20) or (detect(row[10])==\"en\"))):\n",
    "                corpus.append(corpusText)\n",
    "                counter+=1\n",
    "            else:\n",
    "                del data['airline_sentiment'][counter]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizerFunction(filterOrNoFilter):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(filterOrNoFilter,  data['airline_sentiment'], test_size = 0.2)\n",
    "    vectorizer.fit(X_train)\n",
    "    XTrain = vectorizer.transform(X_train)\n",
    "    XTest = vectorizer.transform(X_test)\n",
    "    return XTrain, XTest, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNBClassifier(XTrain, XTest, y_train, y_test):\n",
    "    clf = MultinomialNB(alpha = 1.0, class_prior = None, fit_prior = True)\n",
    "    clf.fit(XTrain, y_train)\n",
    "    predictions = clf.predict(XTest)\n",
    "    score = f1_score(y_test, predictions, average = 'micro')  \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbour Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNeighbourClassifiers(XTrain, XTest, y_train, y_test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "    neigh.fit(XTrain, y_train) \n",
    "    predictions = neigh.predict(XTest)\n",
    "    score = f1_score(y_test, predictions, average = 'micro')  \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RForestClassifiers(XTrain, XTest, y_train, y_test):\n",
    "    clf = RandomForestClassifier(random_state = 0)\n",
    "    clf.fit(XTrain, y_train)\n",
    "    predictions = clf.predict(XTest)\n",
    "    score = f1_score(y_test, predictions, average = 'micro')  \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Tfidf Vectorizer without Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, y_train, y_test = vectorizerFunction(CleanWithoutFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers without Filter F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6705360191191533\n"
     ]
    }
   ],
   "source": [
    "MNBClassifier(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702628883578013\n"
     ]
    }
   ],
   "source": [
    "KNeighbourClassifiers(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andrew\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7412086036189826\n"
     ]
    }
   ],
   "source": [
    "RForestClassifiers(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Tfidf Vectorizer with Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, y_train, y_test = vectorizerFunction(CleanWithFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers with Filter F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "MNBClassifier(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "KNeighbourClassifiers(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andrew\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "RForestClassifiers(XTrain, XTest, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
