{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sally.desktop-ksj9ftc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import uritools\n",
    "import urlextract\n",
    "from langdetect import detect\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Read\n"
     ]
    }
   ],
   "source": [
    "extractor = urlextract.URLExtract()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "data = {'airline_sentiment':[],'text':[]}\n",
    "airline_sentiment = []\n",
    "corpus = []\n",
    "\n",
    "with open('Tweets.csv', 'r', encoding='utf8') as f:\n",
    "    tweets = csv.reader(f)\n",
    "    for row in tweets:        \n",
    "        data['airline_sentiment'].append(row[1])\n",
    "        data['text'].append(row[10])\n",
    "\n",
    "print(\"Data Read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing, Stemming, CaseFolding and Removing Stop Words from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(words):\n",
    "    urls = extractor.find_urls(words+\" \")\n",
    "    for url in urls:\n",
    "        words = words.replace(url,'')\n",
    "    tknzr = TweetTokenizer()\n",
    "    words = tknzr.tokenize(words)\n",
    "    exclude = set(string.punctuation)\n",
    "    words = [word.lower() for word in words if not word.lower() in exclude]\n",
    "    words = [word.lower() for word in words \n",
    "            if not word in set(stopwords.words('english')) and not word.isdigit()]\n",
    "    words = [ps.stem(word) for word in words]\n",
    "    words = ' '.join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(docs):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    Docsdf = vectorizer.fit_transform(docs)\n",
    "    Docsdf = (Docsdf * Docsdf.T).A\n",
    "    a = 1\n",
    "    b = 0\n",
    "    for a in range(len(Docsdf)):\n",
    "        for b in range(a):\n",
    "            x = Docsdf[b][len(Docsdf)-a]\n",
    "            if(x>0.9 and not (len(Docsdf)-a == b)):\n",
    "                del docs[b]\n",
    "                del data['airline_sentiment'][b]\n",
    "                break\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanWithoutFilter():\n",
    "    corpus = []\n",
    "    corpusText=''\n",
    "    with open('Tweets.csv',  encoding='utf8') as File:\n",
    "        spamreader = csv.reader(File)\n",
    "        for row in spamreader:       \n",
    "            corpusText =  clean(row[10])\n",
    "            corpus.append(corpusText)\n",
    "    return corpus\n",
    "\n",
    "def CleanWithFilter():\n",
    "    corpus = []\n",
    "    corpusText=''\n",
    "    counter = 0\n",
    "    with open('Tweets.csv',  encoding='utf8') as File:\n",
    "        spamreader = csv.reader(File)\n",
    "        for row in spamreader:       \n",
    "            corpusText =  clean(row[10])\n",
    "            if(not(corpusText.__contains__(\"RT\") or (len(corpusText )<20) or (detect(row[10])==\"en\"))):\n",
    "                corpus.append(corpusText)\n",
    "                counter+=1\n",
    "            else:\n",
    "                del data['airline_sentiment'][counter]\n",
    "    \n",
    "    corpusFinal = similarity(corpus)\n",
    "    return corpusFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizerFunction(filterOrNoFilter):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(filterOrNoFilter,  data['airline_sentiment'], test_size = 0.2)\n",
    "    vectorizer.fit(X_train)\n",
    "    XTrain = vectorizer.transform(X_train)\n",
    "    XTest = vectorizer.transform(X_test)\n",
    "    return XTrain, XTest, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNBClassifier(XTrain, XTest, y_train, y_test):\n",
    "    clf = MultinomialNB(alpha = 1.0, class_prior = None, fit_prior = True)\n",
    "    clf.fit(XTrain, y_train)\n",
    "    predictions = clf.predict(XTest)\n",
    "    score = f1_score(y_test, predictions, average = 'micro')  \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbour Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNeighbourClassifiers(XTrain, XTest, y_train, y_test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "    neigh.fit(XTrain, y_train) \n",
    "    predictions = neigh.predict(XTest)\n",
    "    score = f1_score(y_test, predictions, average = 'micro')  \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RForestClassifiers(XTrain, XTest, y_train, y_test):\n",
    "    clf = RandomForestClassifier(random_state = 0)\n",
    "    clf.fit(XTrain, y_train)\n",
    "    predictions = clf.predict(XTest)\n",
    "    score = f1_score(y_test, predictions, average = 'micro')  \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Tfidf Vectorizer without Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, y_train, y_test = vectorizerFunction(CleanWithoutFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers without Filter F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6712188460225332\n"
     ]
    }
   ],
   "source": [
    "MNBClassifier(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692045066575623\n"
     ]
    }
   ],
   "source": [
    "KNeighbourClassifiers(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7275520655513827\n"
     ]
    }
   ],
   "source": [
    "RForestClassifiers(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Tfidf Vectorizer with Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, y_train, y_test = vectorizerFunction(CleanWithFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers with Filter F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "MNBClassifier(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "KNeighbourClassifiers(XTrain, XTest, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "RForestClassifiers(XTrain, XTest, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
